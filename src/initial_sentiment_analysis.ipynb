{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as et\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import xmltodict\n",
    "from spacy.lang.tr import Turkish\n",
    "from  spacy.lang.tr.stop_words import STOP_WORDS\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert xml to pandas dataframe\n",
    "def getvalueofnode(node):\n",
    "    return node.text if node is not None else None\n",
    "\n",
    "parsed_xml = et.parse(\"TREMODATA.xml\")\n",
    "dfcols = ['Entry', 'ValidatedEmotion']\n",
    "df_xml = pd.DataFrame(columns=dfcols)\n",
    "\n",
    "for node in parsed_xml.getroot():\n",
    "    entry = node.find('Entry')\n",
    "    validated_emotion = node.find('ValidatedEmotion')\n",
    "    df_xml = df_xml.append(pd.Series([getvalueofnode(entry), getvalueofnode(validated_emotion)], \n",
    "                                     index=dfcols), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build a list of stop words for filtering\n",
    "stopwords = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "parser = Turkish()\n",
    "#parser = spacy.load(\"xx_ent_wiki_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(sentence):\n",
    "    mytokens = parser(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom transformer using spaCy \n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text \n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "vectorizer = CountVectorizer(tokenizer = my_tokenizer, ngram_range=(1,1)) \n",
    "classifier = LinearSVC(max_iter=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>ValidatedEmotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>her yeni gün bir mutluluk</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gece kimsenin olmadığı sokaklardan geçerken ço...</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gerçekleşemeyen hayaller</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arkadaş kaybetmek beni üzüyor</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insanların çıkarcı olmalarından tiksiniyorum</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Entry ValidatedEmotion\n",
       "0                          her yeni gün bir mutluluk            Happy\n",
       "1  gece kimsenin olmadığı sokaklardan geçerken ço...             Fear\n",
       "2                           gerçekleşemeyen hayaller          Sadness\n",
       "3                      arkadaş kaybetmek beni üzüyor          Sadness\n",
       "4       insanların çıkarcı olmalarından tiksiniyorum          Disgust"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting Data Set\n",
    "X = df_xml['Entry']\n",
    "ylabels = df_xml['ValidatedEmotion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)\n",
    "df_xml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8149908592321755\n",
      "Train Accuracy:  0.9775137111517368\n"
     ]
    }
   ],
   "source": [
    "# Create the  pipeline to clean, tokenize, vectorize, and classify using \"Count Vectorizor\"\n",
    "pipe_countvect = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', classifier)])\n",
    "# Fit our data\n",
    "pipe_countvect.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy: \",pipe_countvect.score(X_test,y_test))\n",
    "print(\"Train Accuracy: \",pipe_countvect.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.81 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "#perform cross validation\n",
    "scores = cross_val_score(pipe_countvect, X, ylabels, cv=5)\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xml to json\n",
    "with open(\"TREMODATA.xml\", 'r') as f:\n",
    "    xmlString = f.read()\n",
    "\n",
    "jsonString = json.dumps(xmltodict.parse(xmlString), ensure_ascii=False, indent=4).encode('utf8')\n",
    "with open(\"output.json\", 'w') as f:\n",
    "    f.write(jsonString.decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nicholson gene harika</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mukemmel derece kotu diyen arkadasin sinema bi...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mukemmel derecede kotu bi film hep biselerin o...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nasil begendiginizi anlamiyorum bu filmi filmd...</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ok harika bir film senaryo gereginden fazla ol...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0                            nicholson gene harika       4.0\n",
       "1  mukemmel derece kotu diyen arkadasin sinema bi...     5.0\n",
       "2  mukemmel derecede kotu bi film hep biselerin o...     1.0\n",
       "3  nasil begendiginizi anlamiyorum bu filmi filmd...     1.5\n",
       "4  ok harika bir film senaryo gereginden fazla ol...     5.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate on reviews dataset\n",
    "reviewsfile = 'reviews.xlsx'\n",
    "reviews_df = pd.read_excel(reviewsfile, sheet_name=0, header=0, index_col=False, keep_default_na=True)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.  5.  1.  1.5 3.5 3.  4.5 2.  2.5 0. ]\n",
      "iliskiler uzerine soyleyecek sozu olan enteresan bir film benim beklentilerimi tam karsilamadi ama bir fransiz sinemacisindan istanbul u da izlemek gerek \n"
     ]
    }
   ],
   "source": [
    "ratings = reviews_df.Rating.unique()\n",
    "print(ratings)\n",
    "print(reviews_df.Review[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "X = reviews_df['Review']\n",
    "ylabels = reviews_df['Rating']\n",
    "\n",
    "#encode continuous labels\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "ylabels_enc = lab_enc.fit_transform(ylabels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels_enc, test_size=0.2, random_state=42)\n",
    "print(np.unique(ylabels_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.3100885967419263\n",
      "Train Accuracy:  0.9534509859959989\n"
     ]
    }
   ],
   "source": [
    "pipe_countvect.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy: \", pipe_countvect.score(X_test, y_test))\n",
    "print(\"Train Accuracy: \", pipe_countvect.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.31 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "#perform cross validation\n",
    "scores = cross_val_score(pipe_countvect, X, ylabels_enc, cv=5)\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another random review\n",
    "pipe_countvect.predict([\"cok kotu degil ama yine de bos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ulan Wifi'ye bağlıyım ben. Ona bağlıyken Turkc...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20 dk 1 GB internet 500 mb sadece kaşar turkce...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayrıca turkcell superonline reklamı kadar da k...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkcell çok pahalı ya</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkcell Kaş'ta internetin cekmiyor</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Sentiment\n",
       "0  Ulan Wifi'ye bağlıyım ben. Ona bağlıyken Turkc...   olumsuz\n",
       "1  20 dk 1 GB internet 500 mb sadece kaşar turkce...   olumsuz\n",
       "2  Ayrıca turkcell superonline reklamı kadar da k...   olumsuz\n",
       "3                             Turkcell çok pahalı ya   olumsuz\n",
       "4                Turkcell Kaş'ta internetin cekmiyor   olumsuz"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate on tweets dataset\n",
    "traintweetsfile = 'train_tweets.xlsx'\n",
    "traintweets_df = pd.read_excel(traintweetsfile, sheet_name=0, header=0, index_col=False, keep_default_na=True)\n",
    "traintweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkcell'e kızgınım. Ve bu kızgınlık sanırım a...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkcell kadar şerefsiz misiniz ya</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burdan Turkcell'e sesleniyorum o 3 tl haram olsun</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hayatımda turkcell kadar kazık 1 operatör görm...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkcell gözümde son demlerini yaşıyor hattı d...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Sentiment\n",
       "0  Turkcell'e kızgınım. Ve bu kızgınlık sanırım a...   olumsuz\n",
       "1                 turkcell kadar şerefsiz misiniz ya   olumsuz\n",
       "2  Burdan Turkcell'e sesleniyorum o 3 tl haram olsun   olumsuz\n",
       "3  Hayatımda turkcell kadar kazık 1 operatör görm...   olumsuz\n",
       "4  Turkcell gözümde son demlerini yaşıyor hattı d...   olumsuz"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtweetsfile = 'test_tweets.xlsx'\n",
    "testtweets_df = pd.read_excel(testtweetsfile, sheet_name=0, header=0, index_col=False, keep_default_na=True)\n",
    "testtweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6496962684408447\n",
      "Train Accuracy:  0.9791064198958935\n"
     ]
    }
   ],
   "source": [
    "X_train = traintweets_df['Tweet']\n",
    "y_train = traintweets_df['Sentiment']\n",
    "X_test = testtweets_df['Tweet']\n",
    "y_test = testtweets_df['Sentiment']\n",
    "\n",
    "pipe_countvect.fit(X_train, y_train)\n",
    "\n",
    "'''\n",
    "# Predicting with a test dataset\n",
    "sample_prediction = pipe_countvect.predict(X_test)\n",
    "# Prediction Results\n",
    "for (sample,pred) in zip(X_test,sample_prediction):\n",
    "    print(sample,\"Prediction=>\",pred)\n",
    "'''\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy: \",pipe_countvect.score(X_test, y_test))\n",
    "print(\"Train Accuracy: \",pipe_countvect.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['olumsuz'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another random review\n",
    "pipe_countvect.predict([\"turkcell berbat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.63 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "#perform cross validation\n",
    "X = pd.concat([X_train, X_test])\n",
    "ylabels = pd.concat([y_train, y_test])\n",
    "scores = cross_val_score(pipe_countvect, X, ylabels, cv=5)\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
