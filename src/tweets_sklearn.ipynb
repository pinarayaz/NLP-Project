{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from spacy.lang.tr import Turkish\n",
    "from spacy.lang.tr.stop_words import STOP_WORDS\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ulan Wifi'ye bağlıyım ben. Ona bağlıyken Türkc...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20 dk 1 GB internet 500 mb sadece kaşar türkce...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayrıca türkcell superonline reklamı kadar da k...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Türkcell çok pahalı ya</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Türkcell Kaş'ta internetin çekmiyor</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Sentiment\n",
       "0  Ulan Wifi'ye bağlıyım ben. Ona bağlıyken Türkc...   olumsuz\n",
       "1  20 dk 1 GB internet 500 mb sadece kaşar türkce...   olumsuz\n",
       "2  Ayrıca türkcell superonline reklamı kadar da k...   olumsuz\n",
       "3                             Türkcell çok pahalı ya   olumsuz\n",
       "4                Türkcell Kaş'ta internetin çekmiyor   olumsuz"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetspath = '/Users/pinarayaz/Jupyter/NLP/data/tweets_deasciified.csv'\n",
    "tweets_df = pd.read_csv(tweetspath)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "punctuations = string.punctuation\n",
    "nlp = Turkish()\n",
    "\n",
    "#custom tokenizer for filtering\n",
    "def custom_tokenizer(sentence):\n",
    "    tokens = nlp(sentence)\n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in stopwords and word not in punctuations]\n",
    "    return tokens\n",
    "\n",
    "#custom transformer using spacy \n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "#basic function to clean the text \n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer and classifier\n",
    "vectorizer = CountVectorizer(tokenizer = custom_tokenizer, ngram_range=(1,1)) \n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_df['Tweet']\n",
    "ylabels = tweets_df['Sentiment']\n",
    "\n",
    "#splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cleaner', <__main__.predictors object at 0x1248a4c88>), ('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the pipeline to clean, tokenize, vectorize, and classify using \"Count Vectorizor\"\n",
    "pipeline = Pipeline([(\"cleaner\", predictors()), ('vectorizer', vectorizer), ('classifier', classifier)])\n",
    "\n",
    "#fit our data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.97\n",
      "Test Accuracy: 0.65\n",
      "Precision: 0.34\n",
      "Recall: 0.34\n",
      "F1 Score: 0.34\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "print(\"Train Accuracy: %.2f\" % pipeline.score(X_train, y_train))\n",
    "print(\"Test Accuracy: %.2f\" % pipeline.score(X_test, y_test))\n",
    "\n",
    "#calculate precision, recall, f1 score\n",
    "y_pred = pipeline.predict(y_test)\n",
    "print(\"Precision: %.2f\" % precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Recall: %.2f\" % recall_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"F1 Score: %.2f\" % f1_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.64 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "#perform cross validation\n",
    "scores = cross_val_score(pipeline, X, ylabels, cv=5)\n",
    "print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
