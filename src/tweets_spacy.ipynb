{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.tr import Turkish\n",
    "from spacy.util import minibatch, compounding\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ulan Wifi'ye bağlıyım ben. Ona bağlıyken Türkc...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20 dk 1 GB internet 500 mb sadece kaşar türkce...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayrıca türkcell superonline reklamı kadar da k...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Türkcell çok pahalı ya</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Türkcell Kaş'ta internetin çekmiyor</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Sentiment\n",
       "0  Ulan Wifi'ye bağlıyım ben. Ona bağlıyken Türkc...   olumsuz\n",
       "1  20 dk 1 GB internet 500 mb sadece kaşar türkce...   olumsuz\n",
       "2  Ayrıca türkcell superonline reklamı kadar da k...   olumsuz\n",
       "3                             Türkcell çok pahalı ya   olumsuz\n",
       "4                Türkcell Kaş'ta internetin çekmiyor   olumsuz"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetspath = '/Users/pinarayaz/Jupyter/NLP/data/tweets_deasciified.csv'\n",
    "tweets_df = pd.read_csv(tweetspath)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ulan Wifi'ye bağlıyım ben. Ona bağlıyken Türkcell ınternet paketin bitti diye nasıl mesaj atabilir bana ya? Onu da mı ödeyelim\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = Turkish()\n",
    "sample_review = tweets_df.Tweet[0]\n",
    "sample_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ulan Wifi'ye bağlıyım ben. Ona bağlıyken Türkcell ınternet paketin bitti diye nasıl mesaj atabilir bana ya? Onu da mı ödeyelim"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_review = nlp(sample_review)\n",
    "parsed_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ulan</td>\n",
       "      <td>Ulan</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wifi'ye</td>\n",
       "      <td>(Wifi'ye,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Xxxx'xx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bağlıyım</td>\n",
       "      <td>(bağ,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ben</td>\n",
       "      <td>(ben,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>(.,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text       lemma pos tag dep    shape is_alpha is_stop is_punctuation\n",
       "0      Ulan        Ulan                 Xxxx     True   False          False\n",
       "1   Wifi'ye  (Wifi'ye,)              Xxxx'xx    False   False          False\n",
       "2  bağlıyım      (bağ,)                 xxxx     True   False          False\n",
       "3       ben      (ben,)                  xxx     True    True          False\n",
       "4         .        (.,)                    .    False   False           True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = pd.DataFrame()\n",
    "\n",
    "for i, token in enumerate(parsed_review):\n",
    "    tokenized_text.loc[i, 'text'] = token.text\n",
    "    tokenized_text.loc[i, 'lemma'] = token.lemma_,\n",
    "    tokenized_text.loc[i, 'pos'] = token.pos_\n",
    "    tokenized_text.loc[i, 'tag'] = token.tag_\n",
    "    tokenized_text.loc[i, 'dep'] = token.dep_\n",
    "    tokenized_text.loc[i, 'shape'] = token.shape_\n",
    "    tokenized_text.loc[i, 'is_alpha'] = token.is_alpha\n",
    "    tokenized_text.loc[i, 'is_stop'] = token.is_stop\n",
    "    tokenized_text.loc[i, 'is_punctuation'] = token.is_punct\n",
    "\n",
    "tokenized_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tuples'] = tweets_df.apply(lambda row: (row['Tweet'],row['Sentiment']), axis=1)\n",
    "train = tweets_df['tuples'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"tr\")  # create blank Language class\n",
    "\n",
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe(\"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"})\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat.add_label(\"POSITIVE\")\n",
    "textcat.add_label(\"NEUTRAL\")\n",
    "textcat.add_label(\"NEGATIVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(limit=0, split=0.8):\n",
    "    train_data = train\n",
    "    np.random.shuffle(train_data)\n",
    "    train_data = train_data[-limit:]\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [{\"POSITIVE\": y == \"olumlu\", \"NEUTRAL\": y == \"notr\", \"NEGATIVE\": y == \"olumsuz\"} for y in labels]\n",
    "    split = int(len(train_data) * split)\n",
    "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 1e-8  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 1e-8  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score, 'textcat_a': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tweets dataset...\n",
      "Using 17289 examples (13831 training, 3458 evaluation)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "lim = 17289\n",
    "print(\"Loading Tweets dataset...\")\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=lim)\n",
    "print(\"Using {} examples ({} training, {} evaluation)\".format(lim, len(train_texts), len(dev_texts)))\n",
    "train_data = list(zip(train_texts, [{'cats': cats} for cats in train_cats]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \tAccuracy\n",
      "21.383\t0.713\t0.553\t0.623\t0.777\n",
      "16.540\t0.708\t0.601\t0.650\t0.784\n",
      "12.613\t0.698\t0.615\t0.653\t0.783\n",
      "9.317\t0.688\t0.629\t0.657\t0.781\n",
      "7.354\t0.686\t0.643\t0.664\t0.783\n",
      "5.650\t0.682\t0.655\t0.668\t0.783\n",
      "4.501\t0.679\t0.657\t0.668\t0.782\n",
      "3.891\t0.679\t0.661\t0.670\t0.783\n",
      "3.479\t0.676\t0.659\t0.667\t0.781\n",
      "3.375\t0.677\t0.665\t0.671\t0.783\n"
     ]
    }
   ],
   "source": [
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    print(\"Training the model...\")\n",
    "    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F', 'Accuracy'))\n",
    "    for i in range(10):\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            # evaluate on the dev data split off in load_data()\n",
    "            scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "        print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\\t{4:.3f}'\n",
    "              .format(losses['textcat'], scores['textcat_p'],\n",
    "                      scores['textcat_r'], scores['textcat_f'], scores['textcat_a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bence fiyatlar gayet normal çekim kalitesine göre. dağda bayırda bile çekiyor daha ne olsun! {'POSITIVE': 0.010449743829667568, 'NEUTRAL': 6.190087151480839e-05, 'NEGATIVE': 0.9894883036613464}\n"
     ]
    }
   ],
   "source": [
    "# test the trained model\n",
    "test_text = \"bence fiyatlar gayet normal çekim kalitesine göre. dağda bayırda bile çekiyor daha ne olsun!\"\n",
    "doc = nlp(test_text)\n",
    "print(test_text, doc.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to /Users/pinarayaz/Jupyter/NLP/spacy_models/tweets_spacy\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "output_dir = '/Users/pinarayaz/Jupyter/NLP/spacy_models/tweets_spacy'\n",
    "if output_dir is not None:\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evlat olsun sevilmezsin #Turkcel. Seni çekemicem sanırım , yarın en yakın yerden iptal edicem!!! {'POSITIVE': 0.14946793019771576, 'NEUTRAL': 0.6209986209869385, 'NEGATIVE': 0.22953341901302338}\n",
      "Sentiment: NEUTRAL\n"
     ]
    }
   ],
   "source": [
    "#test the saved model\n",
    "test_text = \"Evlat olsun sevilmezsin #Turkcel. Seni çekemicem sanırım , yarın en yakın yerden iptal edicem!!!\"\n",
    "nlp_test = spacy.load(output_dir)\n",
    "doc2 = nlp_test(test_text)\n",
    "print(test_text, doc2.cats)\n",
    "\n",
    "score = 0\n",
    "for cat in doc2.cats:\n",
    "    if(doc2.cats[cat] > score):\n",
    "        sentiment = cat\n",
    "        score = doc2.cats[cat]\n",
    "print(\"Sentiment:\", sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
