{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kız nutellayı abartıyo sosyal medyasında kendi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ooooo dedikodu alırım bi dal :(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bıkmayacaksın :)</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whatsapp grubuna gelecekler favlasın muhabbetl...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet     Label\n",
       "0  kız nutellayı abartıyo sosyal medyasında kendi...  negative\n",
       "1                    ooooo dedikodu alırım bi dal :(  negative\n",
       "2                                                 :(  negative\n",
       "3                                   bıkmayacaksın :)  positive\n",
       "4  whatsapp grubuna gelecekler favlasın muhabbetl...  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read twt dataset\n",
    "path = '/Users/pinarayaz/Jupyter/NLP/data/twt_preprocessed.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer and classifier\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset\n",
    "X = df['Tweet'].values.astype('U')\n",
    "ylabels = df['Label'].values.astype('U')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the pipeline to vectorize and classify\n",
    "pipeline = Pipeline([('vectorizer', vectorizer),\n",
    "                     ('classifier', classifier)\n",
    "                    ])\n",
    "    \n",
    "#fit our data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.98\n",
      "Test Accuracy: 0.73\n",
      "Precision: 0.50\n",
      "Recall: 0.50\n",
      "F1 Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "print(\"Train Accuracy: %.2f\" % pipeline.score(X_train, y_train))\n",
    "print(\"Test Accuracy: %.2f\" % pipeline.score(X_test, y_test))\n",
    "\n",
    "#calculate precision, recall, f1 score\n",
    "y_pred = pipeline.predict(y_test)\n",
    "print(\"Precision: %.2f\" % precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Recall: %.2f\" % recall_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"F1 Score: %.2f\" % f1_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training spacy blank model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kız nutellayı abartıyo sosyal medyasında kendinden nutella üzgün :(',\n",
       "  'negative'),\n",
       " ('ooooo dedikodu alırım bi dal :(', 'negative'),\n",
       " (':(', 'negative'),\n",
       " ('bıkmayacaksın :)', 'positive'),\n",
       " ('whatsapp grubuna gelecekler favlasın muhabbetler fena :)', 'positive'),\n",
       " ('bebeğim çalışıyorum :(', 'negative'),\n",
       " ('vasip şahin candır :d', 'positive'),\n",
       " ('komsular modemi gec aciyorlar mk :( :( :(', 'negative'),\n",
       " ('ahhhh ketek uler :(', 'negative'),\n",
       " (\"yedi güzel adam yeni günü'nde yeni saatinde pazartesi 55 te ..\",\n",
       "  'positive')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet'] = df['Tweet'].values.astype('U')\n",
    "df['Label'] = df['Label'].values.astype('U')\n",
    "\n",
    "df['tuples'] = df.apply(lambda row: (row['Tweet'], row['Label']), axis=1)\n",
    "train = df['tuples'].tolist()\n",
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"tr\")  # create blank Language class\n",
    "\n",
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe(\"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"})\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "textcat.add_label(\"POSITIVE\")\n",
    "textcat.add_label(\"NEGATIVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(limit=0, split=0.8):\n",
    "    train_data = train\n",
    "    np.random.shuffle(train_data)\n",
    "    train_data = train_data[-limit:]\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [{\"POSITIVE\": y == 'positive', \"NEGATIVE\": y == 'negative'} for y in labels]\n",
    "    split = int(len(train_data) * split)\n",
    "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 1e-8  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 1e-8  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score, 'textcat_a': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 32000 examples (25600 training, 6400 evaluation)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "lim = len(train)\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=lim)\n",
    "print(\"Using {} examples ({} training, {} evaluation)\".format(lim, len(train_texts), len(dev_texts)))\n",
    "train_data = list(zip(train_texts, [{'cats': cats} for cats in train_cats]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \tAccuracy\n",
      "3.670\t0.970\t0.970\t0.970\t0.970\n",
      "1.712\t0.969\t0.969\t0.969\t0.969\n",
      "0.901\t0.972\t0.972\t0.972\t0.972\n",
      "0.581\t0.972\t0.972\t0.972\t0.972\n",
      "0.424\t0.972\t0.972\t0.972\t0.972\n",
      "0.396\t0.973\t0.973\t0.973\t0.973\n",
      "0.316\t0.973\t0.973\t0.973\t0.973\n",
      "0.365\t0.972\t0.972\t0.972\t0.972\n",
      "0.313\t0.973\t0.973\t0.973\t0.973\n",
      "0.290\t0.972\t0.972\t0.972\t0.972\n"
     ]
    }
   ],
   "source": [
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    print(\"Training the model...\")\n",
    "    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F', 'Accuracy'))\n",
    "    for i in range(10):\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            # evaluate on the dev data split off in load_data()\n",
    "            scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "        print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\\t{4:.3f}'\n",
    "              .format(losses['textcat'], scores['textcat_p'],\n",
    "                      scores['textcat_r'], scores['textcat_f'], scores['textcat_a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to /Users/pinarayaz/Jupyter/NLP/spacy_models/twt_spacy\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "output_dir = '/Users/pinarayaz/Jupyter/NLP/spacy_models/twt_spacy'\n",
    "if output_dir is not None:\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lakin bu fani hayatta bize işkence yapmayın be. Midem bulandı resmen. {'POSITIVE': 4.2773812310770154e-05, 'NEGATIVE': 0.9999572038650513}\n",
      "Sentiment: NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "#test the saved model\n",
    "test_text = \"Lakin bu fani hayatta bize işkence yapmayın be. Midem bulandı resmen.\"\n",
    "nlp_test = spacy.load(output_dir)\n",
    "doc2 = nlp_test(test_text)\n",
    "print(test_text, doc2.cats)\n",
    "\n",
    "score = 0\n",
    "for cat in doc2.cats:\n",
    "    if(doc2.cats[cat] > score):\n",
    "        sentiment = cat\n",
    "        score = doc2.cats[cat]\n",
    "print(\"Sentiment:\", sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
