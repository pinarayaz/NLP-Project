{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "path = '/Users/pinarayaz/Jupyter/NLP/data/wiki_embeddings_word2vec.txt'\n",
    "f = open(path, encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/45305384\n",
    "def pre(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "def rec(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "def f1(y_true, y_pred):\n",
    "    precision = pre(y_true, y_pred)\n",
    "    recall = rec(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tremo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>ValidatedEmotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeni gün bir mutlu</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gece ol sokak geç kork</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gerçek hayal</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arkadaş kaybet üz</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insan çıkar ol tiksin</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Entry ValidatedEmotion\n",
       "0      yeni gün bir mutlu            Happy\n",
       "1  gece ol sokak geç kork             Fear\n",
       "2            gerçek hayal          Sadness\n",
       "3       arkadaş kaybet üz          Sadness\n",
       "4   insan çıkar ol tiksin          Disgust"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import tremo dataset\n",
    "tremopath = '/Users/pinarayaz/Jupyter/NLP/data/tremo_preprocessed.csv'\n",
    "tremo_df = pd.read_csv(tremopath)\n",
    "tremo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 55\n",
      "Unique tokens:  7925\n",
      "Shape of entry tensor: (25989, 55)\n",
      "Shape of emotion tensor: (25989,)\n"
     ]
    }
   ],
   "source": [
    "entries = tremo_df['Entry'].values.tolist()\n",
    "max_length = max([len(s.split()) for s in entries])\n",
    "print(\"Max length:\", max_length)\n",
    "\n",
    "#vectorize texts into 2d integer tensor\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(entries)\n",
    "sequences = tokenizer.texts_to_sequences(entries)\n",
    "\n",
    "#pad sequences\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Unique tokens: \", len(word_index))\n",
    "\n",
    "entry_pad = pad_sequences(sequences, maxlen=max_length)\n",
    "emotion = tremo_df['ValidatedEmotion'].values\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "emotion = lab_enc.fit_transform(emotion)\n",
    "\n",
    "print(\"Shape of entry tensor:\", entry_pad.shape)\n",
    "print(\"Shape of emotion tensor:\", emotion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7926\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(num_words,\n",
    "                           EMBEDDING_DIM,\n",
    "                           embeddings_initializer=Constant(embedding_matrix),\n",
    "                           input_length=max_length,\n",
    "                           trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "#optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', pre, rec, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_pad tensor: (20792, 55)\n",
      "Shape of y_train tensor: (20792, 6)\n",
      "Shape of X_test_pad tensor: (5197, 55)\n",
      "Shape of y_test tensor: (5197, 6)\n"
     ]
    }
   ],
   "source": [
    "#split the data\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "indices = np.arange(entry_pad.shape[0])\n",
    "#np.random.shuffle(indices)\n",
    "entry_pad = entry_pad[indices]\n",
    "emotion = emotion[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * entry_pad.shape[0])\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "emotion = to_categorical(emotion, num_classes=6)\n",
    "\n",
    "X_train_pad = entry_pad[:-num_validation_samples]\n",
    "y_train = emotion[:-num_validation_samples]\n",
    "X_test_pad = entry_pad[-num_validation_samples:]\n",
    "y_test = emotion[-num_validation_samples:]\n",
    "print(\"Shape of X_train_pad tensor:\", X_train_pad.shape)\n",
    "print(\"Shape of y_train tensor:\", y_train.shape)\n",
    "print(\"Shape of X_test_pad tensor:\", X_test_pad.shape)\n",
    "print(\"Shape of y_test tensor:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 20792 samples, validate on 5197 samples\n",
      "Epoch 1/50\n",
      " - 13s - loss: 0.3176 - acc: 0.8814 - pre: 0.8085 - rec: 0.3904 - f1: 0.5023 - val_loss: 0.2553 - val_acc: 0.9065 - val_pre: 0.8587 - val_rec: 0.5153 - val_f1: 0.6356\n",
      "Epoch 2/50\n",
      " - 12s - loss: 0.2074 - acc: 0.9267 - pre: 0.8904 - rec: 0.6389 - f1: 0.7426 - val_loss: 0.2192 - val_acc: 0.9158 - val_pre: 0.8389 - val_rec: 0.6028 - val_f1: 0.6970\n",
      "Epoch 3/50\n",
      " - 12s - loss: 0.1792 - acc: 0.9343 - pre: 0.8909 - rec: 0.6904 - f1: 0.7768 - val_loss: 0.2038 - val_acc: 0.9221 - val_pre: 0.8486 - val_rec: 0.6404 - val_f1: 0.7265\n",
      "Epoch 4/50\n",
      " - 12s - loss: 0.1646 - acc: 0.9387 - pre: 0.8913 - rec: 0.7202 - f1: 0.7958 - val_loss: 0.1942 - val_acc: 0.9266 - val_pre: 0.8556 - val_rec: 0.6656 - val_f1: 0.7460\n",
      "Epoch 5/50\n",
      " - 12s - loss: 0.1552 - acc: 0.9418 - pre: 0.8936 - rec: 0.7391 - f1: 0.8083 - val_loss: 0.1890 - val_acc: 0.9278 - val_pre: 0.8493 - val_rec: 0.6823 - val_f1: 0.7544\n",
      "Epoch 6/50\n",
      " - 12s - loss: 0.1499 - acc: 0.9441 - pre: 0.8954 - rec: 0.7527 - f1: 0.8171 - val_loss: 0.1867 - val_acc: 0.9288 - val_pre: 0.8506 - val_rec: 0.6883 - val_f1: 0.7588\n",
      "Epoch 7/50\n",
      " - 12s - loss: 0.1454 - acc: 0.9457 - pre: 0.8956 - rec: 0.7632 - f1: 0.8234 - val_loss: 0.1833 - val_acc: 0.9310 - val_pre: 0.8492 - val_rec: 0.7062 - val_f1: 0.7693\n",
      "Epoch 8/50\n",
      " - 12s - loss: 0.1423 - acc: 0.9461 - pre: 0.8959 - rec: 0.7658 - f1: 0.8250 - val_loss: 0.1811 - val_acc: 0.9313 - val_pre: 0.8477 - val_rec: 0.7104 - val_f1: 0.7713\n",
      "Epoch 9/50\n",
      " - 12s - loss: 0.1387 - acc: 0.9476 - pre: 0.8994 - rec: 0.7726 - f1: 0.8306 - val_loss: 0.1807 - val_acc: 0.9317 - val_pre: 0.8489 - val_rec: 0.7118 - val_f1: 0.7726\n",
      "Epoch 10/50\n",
      " - 12s - loss: 0.1383 - acc: 0.9477 - pre: 0.8973 - rec: 0.7755 - f1: 0.8313 - val_loss: 0.1793 - val_acc: 0.9321 - val_pre: 0.8512 - val_rec: 0.7125 - val_f1: 0.7737\n",
      "Epoch 11/50\n",
      " - 12s - loss: 0.1351 - acc: 0.9490 - pre: 0.8993 - rec: 0.7819 - f1: 0.8359 - val_loss: 0.1774 - val_acc: 0.9330 - val_pre: 0.8499 - val_rec: 0.7208 - val_f1: 0.7783\n",
      "Epoch 12/50\n",
      " - 12s - loss: 0.1331 - acc: 0.9492 - pre: 0.8991 - rec: 0.7835 - f1: 0.8367 - val_loss: 0.1768 - val_acc: 0.9320 - val_pre: 0.8431 - val_rec: 0.7223 - val_f1: 0.7767\n",
      "Epoch 13/50\n",
      " - 12s - loss: 0.1321 - acc: 0.9491 - pre: 0.8971 - rec: 0.7852 - f1: 0.8367 - val_loss: 0.1773 - val_acc: 0.9326 - val_pre: 0.8403 - val_rec: 0.7297 - val_f1: 0.7797\n",
      "Epoch 14/50\n",
      " - 12s - loss: 0.1305 - acc: 0.9499 - pre: 0.8987 - rec: 0.7888 - f1: 0.8396 - val_loss: 0.1762 - val_acc: 0.9332 - val_pre: 0.8485 - val_rec: 0.7237 - val_f1: 0.7795\n",
      "Epoch 15/50\n",
      " - 12s - loss: 0.1291 - acc: 0.9503 - pre: 0.8994 - rec: 0.7904 - f1: 0.8408 - val_loss: 0.1764 - val_acc: 0.9338 - val_pre: 0.8527 - val_rec: 0.7227 - val_f1: 0.7806\n",
      "Epoch 16/50\n",
      " - 12s - loss: 0.1290 - acc: 0.9502 - pre: 0.8984 - rec: 0.7912 - f1: 0.8408 - val_loss: 0.1762 - val_acc: 0.9343 - val_pre: 0.8473 - val_rec: 0.7335 - val_f1: 0.7850\n",
      "Epoch 17/50\n",
      " - 12s - loss: 0.1267 - acc: 0.9520 - pre: 0.9031 - rec: 0.7978 - f1: 0.8466 - val_loss: 0.1750 - val_acc: 0.9341 - val_pre: 0.8462 - val_rec: 0.7333 - val_f1: 0.7843\n",
      "Epoch 18/50\n",
      " - 12s - loss: 0.1260 - acc: 0.9518 - pre: 0.9018 - rec: 0.7981 - f1: 0.8461 - val_loss: 0.1754 - val_acc: 0.9347 - val_pre: 0.8503 - val_rec: 0.7323 - val_f1: 0.7854\n",
      "Epoch 19/50\n",
      " - 12s - loss: 0.1257 - acc: 0.9520 - pre: 0.9024 - rec: 0.7985 - f1: 0.8467 - val_loss: 0.1769 - val_acc: 0.9338 - val_pre: 0.8404 - val_rec: 0.7383 - val_f1: 0.7848\n",
      "Epoch 20/50\n",
      " - 12s - loss: 0.1246 - acc: 0.9520 - pre: 0.9013 - rec: 0.7998 - f1: 0.8469 - val_loss: 0.1738 - val_acc: 0.9342 - val_pre: 0.8467 - val_rec: 0.7333 - val_f1: 0.7845\n",
      "Epoch 21/50\n",
      " - 12s - loss: 0.1231 - acc: 0.9529 - pre: 0.9044 - rec: 0.8024 - f1: 0.8498 - val_loss: 0.1747 - val_acc: 0.9336 - val_pre: 0.8404 - val_rec: 0.7370 - val_f1: 0.7841\n",
      "Epoch 22/50\n",
      " - 12s - loss: 0.1230 - acc: 0.9527 - pre: 0.9024 - rec: 0.8034 - f1: 0.8495 - val_loss: 0.1741 - val_acc: 0.9348 - val_pre: 0.8470 - val_rec: 0.7381 - val_f1: 0.7874\n",
      "Epoch 23/50\n",
      " - 12s - loss: 0.1223 - acc: 0.9531 - pre: 0.9032 - rec: 0.8051 - f1: 0.8506 - val_loss: 0.1731 - val_acc: 0.9346 - val_pre: 0.8455 - val_rec: 0.7377 - val_f1: 0.7867\n",
      "Epoch 24/50\n",
      " - 12s - loss: 0.1226 - acc: 0.9527 - pre: 0.9031 - rec: 0.8025 - f1: 0.8493 - val_loss: 0.1744 - val_acc: 0.9345 - val_pre: 0.8475 - val_rec: 0.7345 - val_f1: 0.7853\n",
      "Epoch 25/50\n",
      " - 12s - loss: 0.1232 - acc: 0.9528 - pre: 0.9023 - rec: 0.8047 - f1: 0.8501 - val_loss: 0.1746 - val_acc: 0.9338 - val_pre: 0.8402 - val_rec: 0.7387 - val_f1: 0.7850\n",
      "Epoch 26/50\n",
      " - 12s - loss: 0.1215 - acc: 0.9537 - pre: 0.9048 - rec: 0.8077 - f1: 0.8529 - val_loss: 0.1735 - val_acc: 0.9347 - val_pre: 0.8399 - val_rec: 0.7462 - val_f1: 0.7891\n",
      "Epoch 27/50\n",
      " - 12s - loss: 0.1217 - acc: 0.9532 - pre: 0.9021 - rec: 0.8070 - f1: 0.8514 - val_loss: 0.1742 - val_acc: 0.9343 - val_pre: 0.8411 - val_rec: 0.7412 - val_f1: 0.7869\n",
      "Epoch 28/50\n",
      " - 12s - loss: 0.1204 - acc: 0.9540 - pre: 0.9031 - rec: 0.8113 - f1: 0.8542 - val_loss: 0.1747 - val_acc: 0.9339 - val_pre: 0.8401 - val_rec: 0.7391 - val_f1: 0.7851\n",
      "Epoch 29/50\n",
      " - 12s - loss: 0.1205 - acc: 0.9538 - pre: 0.9040 - rec: 0.8088 - f1: 0.8532 - val_loss: 0.1741 - val_acc: 0.9351 - val_pre: 0.8410 - val_rec: 0.7475 - val_f1: 0.7905\n",
      "Epoch 30/50\n",
      " - 12s - loss: 0.1186 - acc: 0.9541 - pre: 0.9044 - rec: 0.8106 - f1: 0.8544 - val_loss: 0.1750 - val_acc: 0.9349 - val_pre: 0.8393 - val_rec: 0.7487 - val_f1: 0.7903\n",
      "Epoch 31/50\n",
      " - 12s - loss: 0.1194 - acc: 0.9540 - pre: 0.9030 - rec: 0.8118 - f1: 0.8544 - val_loss: 0.1729 - val_acc: 0.9349 - val_pre: 0.8413 - val_rec: 0.7449 - val_f1: 0.7890\n",
      "Epoch 32/50\n",
      " - 12s - loss: 0.1200 - acc: 0.9536 - pre: 0.9021 - rec: 0.8102 - f1: 0.8531 - val_loss: 0.1727 - val_acc: 0.9350 - val_pre: 0.8406 - val_rec: 0.7472 - val_f1: 0.7900\n",
      "Epoch 33/50\n",
      " - 12s - loss: 0.1191 - acc: 0.9543 - pre: 0.9045 - rec: 0.8114 - f1: 0.8549 - val_loss: 0.1715 - val_acc: 0.9351 - val_pre: 0.8411 - val_rec: 0.7477 - val_f1: 0.7905\n",
      "Epoch 34/50\n",
      " - 12s - loss: 0.1172 - acc: 0.9548 - pre: 0.9035 - rec: 0.8165 - f1: 0.8572 - val_loss: 0.1728 - val_acc: 0.9351 - val_pre: 0.8395 - val_rec: 0.7502 - val_f1: 0.7912\n",
      "Epoch 35/50\n",
      " - 12s - loss: 0.1188 - acc: 0.9541 - pre: 0.9031 - rec: 0.8126 - f1: 0.8548 - val_loss: 0.1721 - val_acc: 0.9360 - val_pre: 0.8483 - val_rec: 0.7454 - val_f1: 0.7923\n",
      "Epoch 36/50\n",
      " - 12s - loss: 0.1172 - acc: 0.9549 - pre: 0.9055 - rec: 0.8146 - f1: 0.8571 - val_loss: 0.1732 - val_acc: 0.9345 - val_pre: 0.8402 - val_rec: 0.7445 - val_f1: 0.7883\n",
      "Epoch 37/50\n",
      " - 12s - loss: 0.1174 - acc: 0.9547 - pre: 0.9038 - rec: 0.8153 - f1: 0.8568 - val_loss: 0.1732 - val_acc: 0.9349 - val_pre: 0.8373 - val_rec: 0.7520 - val_f1: 0.7914\n",
      "Epoch 38/50\n",
      " - 12s - loss: 0.1170 - acc: 0.9547 - pre: 0.9051 - rec: 0.8135 - f1: 0.8563 - val_loss: 0.1732 - val_acc: 0.9354 - val_pre: 0.8405 - val_rec: 0.7506 - val_f1: 0.7917\n",
      "Epoch 39/50\n",
      " - 12s - loss: 0.1178 - acc: 0.9548 - pre: 0.9037 - rec: 0.8165 - f1: 0.8573 - val_loss: 0.1721 - val_acc: 0.9353 - val_pre: 0.8399 - val_rec: 0.7502 - val_f1: 0.7914\n",
      "Epoch 40/50\n",
      " - 12s - loss: 0.1165 - acc: 0.9552 - pre: 0.9058 - rec: 0.8165 - f1: 0.8583 - val_loss: 0.1729 - val_acc: 0.9347 - val_pre: 0.8377 - val_rec: 0.7489 - val_f1: 0.7898\n",
      "Epoch 41/50\n",
      " - 12s - loss: 0.1173 - acc: 0.9545 - pre: 0.9034 - rec: 0.8142 - f1: 0.8560 - val_loss: 0.1723 - val_acc: 0.9357 - val_pre: 0.8387 - val_rec: 0.7556 - val_f1: 0.7940\n",
      "Epoch 42/50\n",
      " - 12s - loss: 0.1174 - acc: 0.9545 - pre: 0.9030 - rec: 0.8147 - f1: 0.8560 - val_loss: 0.1732 - val_acc: 0.9352 - val_pre: 0.8373 - val_rec: 0.7549 - val_f1: 0.7929\n",
      "Epoch 43/50\n",
      " - 12s - loss: 0.1162 - acc: 0.9547 - pre: 0.9030 - rec: 0.8160 - f1: 0.8568 - val_loss: 0.1740 - val_acc: 0.9348 - val_pre: 0.8433 - val_rec: 0.7429 - val_f1: 0.7888\n",
      "Epoch 44/50\n",
      " - 12s - loss: 0.1153 - acc: 0.9555 - pre: 0.9059 - rec: 0.8185 - f1: 0.8595 - val_loss: 0.1744 - val_acc: 0.9351 - val_pre: 0.8422 - val_rec: 0.7470 - val_f1: 0.7906\n",
      "Epoch 45/50\n",
      " - 12s - loss: 0.1165 - acc: 0.9552 - pre: 0.9056 - rec: 0.8166 - f1: 0.8583 - val_loss: 0.1746 - val_acc: 0.9354 - val_pre: 0.8346 - val_rec: 0.7589 - val_f1: 0.7941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      " - 12s - loss: 0.1147 - acc: 0.9555 - pre: 0.9060 - rec: 0.8182 - f1: 0.8594 - val_loss: 0.1742 - val_acc: 0.9352 - val_pre: 0.8371 - val_rec: 0.7535 - val_f1: 0.7921\n",
      "Epoch 47/50\n",
      " - 12s - loss: 0.1143 - acc: 0.9559 - pre: 0.9079 - rec: 0.8189 - f1: 0.8606 - val_loss: 0.1737 - val_acc: 0.9354 - val_pre: 0.8414 - val_rec: 0.7497 - val_f1: 0.7918\n",
      "Epoch 48/50\n",
      " - 12s - loss: 0.1151 - acc: 0.9550 - pre: 0.9031 - rec: 0.8180 - f1: 0.8579 - val_loss: 0.1739 - val_acc: 0.9350 - val_pre: 0.8353 - val_rec: 0.7552 - val_f1: 0.7923\n",
      "Epoch 49/50\n",
      " - 12s - loss: 0.1155 - acc: 0.9552 - pre: 0.9042 - rec: 0.8185 - f1: 0.8587 - val_loss: 0.1726 - val_acc: 0.9354 - val_pre: 0.8387 - val_rec: 0.7529 - val_f1: 0.7925\n",
      "Epoch 50/50\n",
      " - 11s - loss: 0.1140 - acc: 0.9560 - pre: 0.9065 - rec: 0.8216 - f1: 0.8613 - val_loss: 0.1740 - val_acc: 0.9345 - val_pre: 0.8338 - val_rec: 0.7533 - val_f1: 0.7905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126343710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train_pad, y_train, batch_size=64, epochs=50, validation_data=(X_test_pad, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[773  28  48  50  29  20]\n",
      " [ 28 612  31  15   5   5]\n",
      " [ 34  15 705  37  43  10]\n",
      " [ 47  25  40 920  32  39]\n",
      " [ 74  16  71 129 802  18]\n",
      " [ 31  10  21  78  23 333]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "y_pred = model.predict(X_test_pad)\n",
    "matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Happy' 'Fear' 'Sadness' ... 'Fear' 'Anger' 'Surprise']\n"
     ]
    }
   ],
   "source": [
    "#get y_pred for meta layer\n",
    "all_pred = model.predict(entry_pad)\n",
    "decoded = lab_enc.inverse_transform(all_pred.argmax(axis=1))\n",
    "print(decoded)\n",
    "(pd.DataFrame(decoded)).to_csv('predictions.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## twt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kız nutellayı abartıyo sosyal medya nutella üz...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ooooo dedikodu al bi dal :(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bıkmayacaksın :)</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whatsapp grup gelecek favlasın muhabbet fena :)</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet     Label\n",
       "0  kız nutellayı abartıyo sosyal medya nutella üz...  negative\n",
       "1                        ooooo dedikodu al bi dal :(  negative\n",
       "2                                                 :(  negative\n",
       "3                                   bıkmayacaksın :)  positive\n",
       "4    whatsapp grup gelecek favlasın muhabbet fena :)  positive"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read twt dataset\n",
    "twtpath = '/Users/pinarayaz/Jupyter/NLP/data/twt_preprocessed.csv'\n",
    "twt_df = pd.read_csv(twtpath)\n",
    "twt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 28\n",
      "Unique tokens:  27809\n",
      "Shape of entry tensor: (32000, 28)\n",
      "Shape of emotion tensor: (32000,)\n"
     ]
    }
   ],
   "source": [
    "entries = twt_df['Tweet'].values.astype('U').tolist()\n",
    "max_length = max([len(s.split()) for s in entries])\n",
    "print(\"Max length:\", max_length)\n",
    "\n",
    "#vectorize texts into 2d integer tensor\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(entries)\n",
    "sequences = tokenizer.texts_to_sequences(entries)\n",
    "\n",
    "#pad sequences\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Unique tokens: \", len(word_index))\n",
    "\n",
    "entry_pad = pad_sequences(sequences, maxlen=max_length)\n",
    "emotion = twt_df['Label'].values.astype('U')\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "emotion = lab_enc.fit_transform(emotion)\n",
    "\n",
    "print(\"Shape of entry tensor:\", entry_pad.shape)\n",
    "print(\"Shape of emotion tensor:\", emotion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27810\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(num_words,\n",
    "                           EMBEDDING_DIM,\n",
    "                           embeddings_initializer=Constant(embedding_matrix),\n",
    "                           input_length=max_length,\n",
    "                           trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', pre, rec, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_pad tensor: (25600, 28)\n",
      "Shape of y_train tensor: (25600,)\n",
      "Shape of X_test_pad tensor: (6400, 28)\n",
      "Shape of y_test tensor: (6400,)\n"
     ]
    }
   ],
   "source": [
    "#split the data\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "indices = np.arange(entry_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "entry_pad = entry_pad[indices]\n",
    "emotion = emotion[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * entry_pad.shape[0])\n",
    "\n",
    "X_train_pad = entry_pad[:-num_validation_samples]\n",
    "y_train = emotion[:-num_validation_samples]\n",
    "X_test_pad = entry_pad[-num_validation_samples:]\n",
    "y_test = emotion[-num_validation_samples:]\n",
    "print(\"Shape of X_train_pad tensor:\", X_train_pad.shape)\n",
    "print(\"Shape of y_train tensor:\", y_train.shape)\n",
    "print(\"Shape of X_test_pad tensor:\", X_test_pad.shape)\n",
    "print(\"Shape of y_test tensor:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25600 samples, validate on 6400 samples\n",
      "Epoch 1/50\n",
      " - 10s - loss: 0.6256 - acc: 0.6368 - pre: 0.6346 - rec: 0.6573 - f1: 0.6385 - val_loss: 0.5627 - val_acc: 0.6934 - val_pre: 0.6917 - val_rec: 0.6960 - val_f1: 0.6903\n",
      "Epoch 2/50\n",
      " - 8s - loss: 0.5606 - acc: 0.6986 - pre: 0.7099 - rec: 0.6726 - f1: 0.6869 - val_loss: 0.5318 - val_acc: 0.7113 - val_pre: 0.7208 - val_rec: 0.6889 - val_f1: 0.7009\n",
      "Epoch 3/50\n",
      " - 8s - loss: 0.5338 - acc: 0.7170 - pre: 0.7359 - rec: 0.6805 - f1: 0.7035 - val_loss: 0.5176 - val_acc: 0.7242 - val_pre: 0.7515 - val_rec: 0.6691 - val_f1: 0.7044\n",
      "Epoch 4/50\n",
      " - 8s - loss: 0.5158 - acc: 0.7269 - pre: 0.7464 - rec: 0.6890 - f1: 0.7125 - val_loss: 0.5074 - val_acc: 0.7342 - val_pre: 0.7466 - val_rec: 0.7112 - val_f1: 0.7251\n",
      "Epoch 5/50\n",
      " - 8s - loss: 0.5048 - acc: 0.7325 - pre: 0.7529 - rec: 0.6952 - f1: 0.7193 - val_loss: 0.5016 - val_acc: 0.7348 - val_pre: 0.7522 - val_rec: 0.7035 - val_f1: 0.7235\n",
      "Epoch 6/50\n",
      " - 8s - loss: 0.4953 - acc: 0.7415 - pre: 0.7627 - rec: 0.6999 - f1: 0.7263 - val_loss: 0.4969 - val_acc: 0.7344 - val_pre: 0.7548 - val_rec: 0.6985 - val_f1: 0.7215\n",
      "Epoch 7/50\n",
      " - 8s - loss: 0.4884 - acc: 0.7491 - pre: 0.7731 - rec: 0.7088 - f1: 0.7354 - val_loss: 0.4940 - val_acc: 0.7405 - val_pre: 0.7737 - val_rec: 0.6825 - val_f1: 0.7213\n",
      "Epoch 8/50\n",
      " - 8s - loss: 0.4829 - acc: 0.7490 - pre: 0.7717 - rec: 0.7081 - f1: 0.7350 - val_loss: 0.4943 - val_acc: 0.7370 - val_pre: 0.7447 - val_rec: 0.7236 - val_f1: 0.7309\n",
      "Epoch 9/50\n",
      " - 8s - loss: 0.4795 - acc: 0.7515 - pre: 0.7743 - rec: 0.7096 - f1: 0.7372 - val_loss: 0.4928 - val_acc: 0.7412 - val_pre: 0.7609 - val_rec: 0.7066 - val_f1: 0.7291\n",
      "Epoch 10/50\n",
      " - 8s - loss: 0.4704 - acc: 0.7571 - pre: 0.7790 - rec: 0.7185 - f1: 0.7440 - val_loss: 0.4915 - val_acc: 0.7383 - val_pre: 0.7675 - val_rec: 0.6853 - val_f1: 0.7208\n",
      "Epoch 11/50\n",
      " - 8s - loss: 0.4689 - acc: 0.7570 - pre: 0.7812 - rec: 0.7157 - f1: 0.7439 - val_loss: 0.4920 - val_acc: 0.7375 - val_pre: 0.7491 - val_rec: 0.7170 - val_f1: 0.7293\n",
      "Epoch 12/50\n",
      " - 8s - loss: 0.4655 - acc: 0.7593 - pre: 0.7819 - rec: 0.7211 - f1: 0.7466 - val_loss: 0.4898 - val_acc: 0.7450 - val_pre: 0.7729 - val_rec: 0.6969 - val_f1: 0.7294\n",
      "Epoch 13/50\n",
      " - 8s - loss: 0.4610 - acc: 0.7623 - pre: 0.7844 - rec: 0.7254 - f1: 0.7502 - val_loss: 0.4917 - val_acc: 0.7436 - val_pre: 0.7963 - val_rec: 0.6552 - val_f1: 0.7148\n",
      "Epoch 14/50\n",
      " - 8s - loss: 0.4566 - acc: 0.7625 - pre: 0.7861 - rec: 0.7215 - f1: 0.7493 - val_loss: 0.4877 - val_acc: 0.7505 - val_pre: 0.7876 - val_rec: 0.6867 - val_f1: 0.7301\n",
      "Epoch 15/50\n",
      " - 8s - loss: 0.4573 - acc: 0.7642 - pre: 0.7883 - rec: 0.7241 - f1: 0.7514 - val_loss: 0.4905 - val_acc: 0.7475 - val_pre: 0.7909 - val_rec: 0.6740 - val_f1: 0.7237\n",
      "Epoch 16/50\n",
      " - 8s - loss: 0.4522 - acc: 0.7678 - pre: 0.7924 - rec: 0.7292 - f1: 0.7562 - val_loss: 0.4893 - val_acc: 0.7452 - val_pre: 0.7876 - val_rec: 0.6713 - val_f1: 0.7210\n",
      "Epoch 17/50\n",
      " - 8s - loss: 0.4508 - acc: 0.7663 - pre: 0.7914 - rec: 0.7256 - f1: 0.7538 - val_loss: 0.4900 - val_acc: 0.7448 - val_pre: 0.7854 - val_rec: 0.6729 - val_f1: 0.7211\n",
      "Epoch 18/50\n",
      " - 8s - loss: 0.4500 - acc: 0.7665 - pre: 0.7909 - rec: 0.7261 - f1: 0.7535 - val_loss: 0.4871 - val_acc: 0.7453 - val_pre: 0.7777 - val_rec: 0.6867 - val_f1: 0.7261\n",
      "Epoch 19/50\n",
      " - 8s - loss: 0.4453 - acc: 0.7711 - pre: 0.7953 - rec: 0.7309 - f1: 0.7585 - val_loss: 0.4878 - val_acc: 0.7497 - val_pre: 0.7719 - val_rec: 0.7102 - val_f1: 0.7364\n",
      "Epoch 20/50\n",
      " - 8s - loss: 0.4476 - acc: 0.7713 - pre: 0.7963 - rec: 0.7307 - f1: 0.7590 - val_loss: 0.4874 - val_acc: 0.7430 - val_pre: 0.7719 - val_rec: 0.6905 - val_f1: 0.7256\n",
      "Epoch 21/50\n",
      " - 8s - loss: 0.4448 - acc: 0.7697 - pre: 0.7933 - rec: 0.7309 - f1: 0.7575 - val_loss: 0.4870 - val_acc: 0.7414 - val_pre: 0.7575 - val_rec: 0.7102 - val_f1: 0.7297\n",
      "Epoch 22/50\n",
      " - 8s - loss: 0.4385 - acc: 0.7758 - pre: 0.7969 - rec: 0.7417 - f1: 0.7649 - val_loss: 0.4899 - val_acc: 0.7469 - val_pre: 0.7823 - val_rec: 0.6845 - val_f1: 0.7264\n",
      "Epoch 23/50\n",
      " - 8s - loss: 0.4379 - acc: 0.7797 - pre: 0.8041 - rec: 0.7403 - f1: 0.7680 - val_loss: 0.4882 - val_acc: 0.7495 - val_pre: 0.7748 - val_rec: 0.7033 - val_f1: 0.7340\n",
      "Epoch 24/50\n",
      " - 8s - loss: 0.4340 - acc: 0.7799 - pre: 0.8042 - rec: 0.7415 - f1: 0.7686 - val_loss: 0.4908 - val_acc: 0.7392 - val_pre: 0.7500 - val_rec: 0.7167 - val_f1: 0.7299\n",
      "Epoch 25/50\n",
      " - 8s - loss: 0.4386 - acc: 0.7762 - pre: 0.7979 - rec: 0.7423 - f1: 0.7656 - val_loss: 0.4913 - val_acc: 0.7484 - val_pre: 0.8028 - val_rec: 0.6568 - val_f1: 0.7189\n",
      "Epoch 26/50\n",
      " - 8s - loss: 0.4330 - acc: 0.7793 - pre: 0.8033 - rec: 0.7403 - f1: 0.7674 - val_loss: 0.4927 - val_acc: 0.7459 - val_pre: 0.7826 - val_rec: 0.6790 - val_f1: 0.7234\n",
      "Epoch 27/50\n",
      " - 8s - loss: 0.4354 - acc: 0.7801 - pre: 0.8047 - rec: 0.7408 - f1: 0.7684 - val_loss: 0.4900 - val_acc: 0.7483 - val_pre: 0.7768 - val_rec: 0.6954 - val_f1: 0.7308\n",
      "Epoch 28/50\n",
      " - 8s - loss: 0.4327 - acc: 0.7810 - pre: 0.8064 - rec: 0.7413 - f1: 0.7693 - val_loss: 0.4902 - val_acc: 0.7439 - val_pre: 0.7683 - val_rec: 0.6973 - val_f1: 0.7277\n",
      "Epoch 29/50\n",
      " - 8s - loss: 0.4301 - acc: 0.7812 - pre: 0.8046 - rec: 0.7441 - f1: 0.7702 - val_loss: 0.4923 - val_acc: 0.7483 - val_pre: 0.7923 - val_rec: 0.6728 - val_f1: 0.7242\n",
      "Epoch 30/50\n",
      " - 8s - loss: 0.4350 - acc: 0.7774 - pre: 0.8010 - rec: 0.7391 - f1: 0.7658 - val_loss: 0.4897 - val_acc: 0.7467 - val_pre: 0.7727 - val_rec: 0.6989 - val_f1: 0.7305\n",
      "Epoch 31/50\n",
      " - 8s - loss: 0.4267 - acc: 0.7832 - pre: 0.8036 - rec: 0.7497 - f1: 0.7729 - val_loss: 0.4946 - val_acc: 0.7477 - val_pre: 0.8004 - val_rec: 0.6592 - val_f1: 0.7192\n",
      "Epoch 32/50\n",
      " - 8s - loss: 0.4295 - acc: 0.7833 - pre: 0.8079 - rec: 0.7431 - f1: 0.7711 - val_loss: 0.4927 - val_acc: 0.7409 - val_pre: 0.7427 - val_rec: 0.7393 - val_f1: 0.7375\n",
      "Epoch 33/50\n",
      " - 8s - loss: 0.4275 - acc: 0.7845 - pre: 0.8074 - rec: 0.7469 - f1: 0.7728 - val_loss: 0.4910 - val_acc: 0.7428 - val_pre: 0.7489 - val_rec: 0.7286 - val_f1: 0.7357\n",
      "Epoch 34/50\n",
      " - 8s - loss: 0.4278 - acc: 0.7833 - pre: 0.8077 - rec: 0.7442 - f1: 0.7715 - val_loss: 0.4921 - val_acc: 0.7478 - val_pre: 0.7705 - val_rec: 0.7053 - val_f1: 0.7328\n",
      "Epoch 35/50\n",
      " - 8s - loss: 0.4220 - acc: 0.7876 - pre: 0.8109 - rec: 0.7516 - f1: 0.7771 - val_loss: 0.4939 - val_acc: 0.7522 - val_pre: 0.7708 - val_rec: 0.7187 - val_f1: 0.7405\n",
      "Epoch 36/50\n",
      " - 8s - loss: 0.4240 - acc: 0.7875 - pre: 0.8104 - rec: 0.7522 - f1: 0.7767 - val_loss: 0.4949 - val_acc: 0.7470 - val_pre: 0.7837 - val_rec: 0.6814 - val_f1: 0.7252\n",
      "Epoch 37/50\n",
      " - 8s - loss: 0.4216 - acc: 0.7903 - pre: 0.8143 - rec: 0.7550 - f1: 0.7805 - val_loss: 0.4953 - val_acc: 0.7473 - val_pre: 0.7738 - val_rec: 0.6989 - val_f1: 0.7310\n",
      "Epoch 38/50\n",
      " - 8s - loss: 0.4226 - acc: 0.7870 - pre: 0.8082 - rec: 0.7527 - f1: 0.7769 - val_loss: 0.4963 - val_acc: 0.7466 - val_pre: 0.7742 - val_rec: 0.6961 - val_f1: 0.7297\n",
      "Epoch 39/50\n",
      " - 8s - loss: 0.4235 - acc: 0.7881 - pre: 0.8135 - rec: 0.7474 - f1: 0.7762 - val_loss: 0.4931 - val_acc: 0.7484 - val_pre: 0.7702 - val_rec: 0.7079 - val_f1: 0.7347\n",
      "Epoch 40/50\n",
      " - 8s - loss: 0.4199 - acc: 0.7864 - pre: 0.8097 - rec: 0.7485 - f1: 0.7753 - val_loss: 0.4931 - val_acc: 0.7497 - val_pre: 0.7809 - val_rec: 0.6930 - val_f1: 0.7310\n",
      "Epoch 41/50\n",
      " - 8s - loss: 0.4194 - acc: 0.7896 - pre: 0.8134 - rec: 0.7533 - f1: 0.7795 - val_loss: 0.4933 - val_acc: 0.7455 - val_pre: 0.7661 - val_rec: 0.7088 - val_f1: 0.7328\n",
      "Epoch 42/50\n",
      " - 8s - loss: 0.4237 - acc: 0.7872 - pre: 0.8101 - rec: 0.7524 - f1: 0.7770 - val_loss: 0.4939 - val_acc: 0.7459 - val_pre: 0.7845 - val_rec: 0.6803 - val_f1: 0.7243\n",
      "Epoch 43/50\n",
      " - 8s - loss: 0.4192 - acc: 0.7900 - pre: 0.8134 - rec: 0.7549 - f1: 0.7803 - val_loss: 0.4921 - val_acc: 0.7461 - val_pre: 0.7831 - val_rec: 0.6815 - val_f1: 0.7249\n",
      "Epoch 44/50\n",
      " - 8s - loss: 0.4175 - acc: 0.7907 - pre: 0.8149 - rec: 0.7516 - f1: 0.7791 - val_loss: 0.4940 - val_acc: 0.7455 - val_pre: 0.7578 - val_rec: 0.7230 - val_f1: 0.7364\n",
      "Epoch 45/50\n",
      " - 8s - loss: 0.4204 - acc: 0.7880 - pre: 0.8106 - rec: 0.7520 - f1: 0.7774 - val_loss: 0.4992 - val_acc: 0.7458 - val_pre: 0.8004 - val_rec: 0.6548 - val_f1: 0.7161\n",
      "Epoch 46/50\n",
      " - 8s - loss: 0.4155 - acc: 0.7909 - pre: 0.8152 - rec: 0.7526 - f1: 0.7798 - val_loss: 0.4961 - val_acc: 0.7445 - val_pre: 0.7843 - val_rec: 0.6755 - val_f1: 0.7218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      " - 8s - loss: 0.4176 - acc: 0.7893 - pre: 0.8120 - rec: 0.7517 - f1: 0.7777 - val_loss: 0.4954 - val_acc: 0.7470 - val_pre: 0.7908 - val_rec: 0.6738 - val_f1: 0.7234\n",
      "Epoch 48/50\n",
      " - 8s - loss: 0.4141 - acc: 0.7929 - pre: 0.8169 - rec: 0.7550 - f1: 0.7817 - val_loss: 0.4970 - val_acc: 0.7436 - val_pre: 0.7574 - val_rec: 0.7188 - val_f1: 0.7343\n",
      "Epoch 49/50\n",
      " - 8s - loss: 0.4136 - acc: 0.7927 - pre: 0.8158 - rec: 0.7568 - f1: 0.7825 - val_loss: 0.4998 - val_acc: 0.7491 - val_pre: 0.7914 - val_rec: 0.6770 - val_f1: 0.7261\n",
      "Epoch 50/50\n",
      " - 8s - loss: 0.4152 - acc: 0.7914 - pre: 0.8149 - rec: 0.7521 - f1: 0.7793 - val_loss: 0.4955 - val_acc: 0.7486 - val_pre: 0.7940 - val_rec: 0.6728 - val_f1: 0.7238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x133b350f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train_pad, y_train, batch_size=64, epochs=50, validation_data=(X_test_pad, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2645  563]\n",
      " [1046 2146]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "y_pred = model.predict_classes(X_test_pad)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ulan wifi'ye bağ bağ türkcell ınternet paket b...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20 dk 1 gb internet 500 mb kaşar türkcell düş ...</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>türkcell superonline reklam kötü bir reklam gör</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>türkcell paha</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>türkcell kaş'ta internet çek</td>\n",
       "      <td>olumsuz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Sentiment\n",
       "0  ulan wifi'ye bağ bağ türkcell ınternet paket b...   olumsuz\n",
       "1  20 dk 1 gb internet 500 mb kaşar türkcell düş ...   olumsuz\n",
       "2    türkcell superonline reklam kötü bir reklam gör   olumsuz\n",
       "3                                      türkcell paha   olumsuz\n",
       "4                       türkcell kaş'ta internet çek   olumsuz"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import tweets dataset\n",
    "tweetspath = '/Users/pinarayaz/Jupyter/NLP/data/tweets_preprocessed.csv'\n",
    "tweets_df = pd.read_csv(tweetspath)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 37\n",
      "Unique tokens:  25984\n",
      "Shape of entry tensor: (17289, 37)\n",
      "Shape of emotion tensor: (17289,)\n"
     ]
    }
   ],
   "source": [
    "entries = tweets_df['Tweet'].values.tolist()\n",
    "max_length = max([len(s.split()) for s in entries])\n",
    "print(\"Max length:\", max_length)\n",
    "\n",
    "#vectorize texts into 2d integer tensor\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(entries)\n",
    "sequences = tokenizer.texts_to_sequences(entries)\n",
    "\n",
    "#pad sequences\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Unique tokens: \", len(word_index))\n",
    "\n",
    "entry_pad = pad_sequences(sequences, maxlen=max_length)\n",
    "emotion = tweets_df['Sentiment'].values\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "emotion = lab_enc.fit_transform(emotion)\n",
    "\n",
    "print(\"Shape of entry tensor:\", entry_pad.shape)\n",
    "print(\"Shape of emotion tensor:\", emotion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25985\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(num_words,\n",
    "                           EMBEDDING_DIM,\n",
    "                           embeddings_initializer=Constant(embedding_matrix),\n",
    "                           input_length=max_length,\n",
    "                           trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "#optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', pre, rec, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_pad tensor: (13832, 37)\n",
      "Shape of y_train tensor: (13832, 3)\n",
      "Shape of X_test_pad tensor: (3457, 37)\n",
      "Shape of y_test tensor: (3457, 3)\n"
     ]
    }
   ],
   "source": [
    "#split the data\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "indices = np.arange(entry_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "entry_pad = entry_pad[indices]\n",
    "emotion = emotion[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * entry_pad.shape[0])\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "emotion = to_categorical(emotion, num_classes=3)\n",
    "\n",
    "X_train_pad = entry_pad[:-num_validation_samples]\n",
    "y_train = emotion[:-num_validation_samples]\n",
    "X_test_pad = entry_pad[-num_validation_samples:]\n",
    "y_test = emotion[-num_validation_samples:]\n",
    "print(\"Shape of X_train_pad tensor:\", X_train_pad.shape)\n",
    "print(\"Shape of y_train tensor:\", y_train.shape)\n",
    "print(\"Shape of X_test_pad tensor:\", X_test_pad.shape)\n",
    "print(\"Shape of y_test tensor:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13832 samples, validate on 3457 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 0.6150 - acc: 0.6736 - pre: 0.5375 - rec: 0.1995 - f1: 0.2860 - val_loss: 0.5630 - val_acc: 0.7206 - val_pre: 0.6732 - val_rec: 0.3141 - val_f1: 0.4262\n",
      "Epoch 2/50\n",
      " - 6s - loss: 0.5638 - acc: 0.7170 - pre: 0.6365 - rec: 0.3525 - f1: 0.4517 - val_loss: 0.5359 - val_acc: 0.7401 - val_pre: 0.6901 - val_rec: 0.4024 - val_f1: 0.5066\n",
      "Epoch 3/50\n",
      " - 5s - loss: 0.5414 - acc: 0.7328 - pre: 0.6543 - rec: 0.4200 - f1: 0.5103 - val_loss: 0.5191 - val_acc: 0.7501 - val_pre: 0.6834 - val_rec: 0.4675 - val_f1: 0.5540\n",
      "Epoch 4/50\n",
      " - 6s - loss: 0.5282 - acc: 0.7414 - pre: 0.6679 - rec: 0.4479 - f1: 0.5350 - val_loss: 0.5111 - val_acc: 0.7576 - val_pre: 0.6992 - val_rec: 0.4811 - val_f1: 0.5691\n",
      "Epoch 5/50\n",
      " - 6s - loss: 0.5181 - acc: 0.7494 - pre: 0.6777 - rec: 0.4731 - f1: 0.5559 - val_loss: 0.5060 - val_acc: 0.7587 - val_pre: 0.6964 - val_rec: 0.4915 - val_f1: 0.5753\n",
      "Epoch 6/50\n",
      " - 6s - loss: 0.5094 - acc: 0.7546 - pre: 0.6892 - rec: 0.4813 - f1: 0.5658 - val_loss: 0.5009 - val_acc: 0.7608 - val_pre: 0.6910 - val_rec: 0.5132 - val_f1: 0.5877\n",
      "Epoch 7/50\n",
      " - 5s - loss: 0.5037 - acc: 0.7581 - pre: 0.6883 - rec: 0.5020 - f1: 0.5795 - val_loss: 0.4994 - val_acc: 0.7618 - val_pre: 0.7026 - val_rec: 0.4970 - val_f1: 0.5814\n",
      "Epoch 8/50\n",
      " - 5s - loss: 0.4985 - acc: 0.7618 - pre: 0.6980 - rec: 0.5035 - f1: 0.5840 - val_loss: 0.4952 - val_acc: 0.7649 - val_pre: 0.6982 - val_rec: 0.5204 - val_f1: 0.5954\n",
      "Epoch 9/50\n",
      " - 6s - loss: 0.4938 - acc: 0.7641 - pre: 0.7009 - rec: 0.5111 - f1: 0.5900 - val_loss: 0.4931 - val_acc: 0.7651 - val_pre: 0.6931 - val_rec: 0.5320 - val_f1: 0.6011\n",
      "Epoch 10/50\n",
      " - 6s - loss: 0.4908 - acc: 0.7687 - pre: 0.7089 - rec: 0.5200 - f1: 0.5989 - val_loss: 0.4922 - val_acc: 0.7671 - val_pre: 0.7028 - val_rec: 0.5239 - val_f1: 0.5993\n",
      "Epoch 11/50\n",
      " - 6s - loss: 0.4863 - acc: 0.7695 - pre: 0.7081 - rec: 0.5247 - f1: 0.6017 - val_loss: 0.4905 - val_acc: 0.7673 - val_pre: 0.7026 - val_rec: 0.5256 - val_f1: 0.6004\n",
      "Epoch 12/50\n",
      " - 6s - loss: 0.4843 - acc: 0.7708 - pre: 0.7077 - rec: 0.5318 - f1: 0.6064 - val_loss: 0.4903 - val_acc: 0.7693 - val_pre: 0.7043 - val_rec: 0.5314 - val_f1: 0.6049\n",
      "Epoch 13/50\n",
      " - 5s - loss: 0.4783 - acc: 0.7758 - pre: 0.7182 - rec: 0.5394 - f1: 0.6151 - val_loss: 0.4866 - val_acc: 0.7702 - val_pre: 0.7001 - val_rec: 0.5444 - val_f1: 0.6118\n",
      "Epoch 14/50\n",
      " - 6s - loss: 0.4796 - acc: 0.7725 - pre: 0.7103 - rec: 0.5367 - f1: 0.6104 - val_loss: 0.4862 - val_acc: 0.7704 - val_pre: 0.7033 - val_rec: 0.5386 - val_f1: 0.6091\n",
      "Epoch 15/50\n",
      " - 6s - loss: 0.4760 - acc: 0.7747 - pre: 0.7175 - rec: 0.5365 - f1: 0.6130 - val_loss: 0.4855 - val_acc: 0.7705 - val_pre: 0.7043 - val_rec: 0.5369 - val_f1: 0.6086\n",
      "Epoch 16/50\n",
      " - 6s - loss: 0.4717 - acc: 0.7757 - pre: 0.7145 - rec: 0.5450 - f1: 0.6174 - val_loss: 0.4869 - val_acc: 0.7703 - val_pre: 0.7067 - val_rec: 0.5320 - val_f1: 0.6060\n",
      "Epoch 17/50\n",
      " - 6s - loss: 0.4690 - acc: 0.7796 - pre: 0.7230 - rec: 0.5510 - f1: 0.6245 - val_loss: 0.4872 - val_acc: 0.7682 - val_pre: 0.6971 - val_rec: 0.5380 - val_f1: 0.6066\n",
      "Epoch 18/50\n",
      " - 5s - loss: 0.4659 - acc: 0.7814 - pre: 0.7252 - rec: 0.5559 - f1: 0.6285 - val_loss: 0.4837 - val_acc: 0.7693 - val_pre: 0.6996 - val_rec: 0.5383 - val_f1: 0.6075\n",
      "Epoch 19/50\n",
      " - 5s - loss: 0.4630 - acc: 0.7827 - pre: 0.7248 - rec: 0.5612 - f1: 0.6318 - val_loss: 0.4870 - val_acc: 0.7695 - val_pre: 0.6992 - val_rec: 0.5404 - val_f1: 0.6087\n",
      "Epoch 20/50\n",
      " - 5s - loss: 0.4619 - acc: 0.7813 - pre: 0.7233 - rec: 0.5578 - f1: 0.6288 - val_loss: 0.4857 - val_acc: 0.7710 - val_pre: 0.6971 - val_rec: 0.5525 - val_f1: 0.6157\n",
      "Epoch 21/50\n",
      " - 5s - loss: 0.4627 - acc: 0.7838 - pre: 0.7279 - rec: 0.5616 - f1: 0.6332 - val_loss: 0.4855 - val_acc: 0.7716 - val_pre: 0.6938 - val_rec: 0.5620 - val_f1: 0.6203\n",
      "Epoch 22/50\n",
      " - 5s - loss: 0.4592 - acc: 0.7845 - pre: 0.7281 - rec: 0.5651 - f1: 0.6354 - val_loss: 0.4848 - val_acc: 0.7708 - val_pre: 0.7028 - val_rec: 0.5421 - val_f1: 0.6111\n",
      "Epoch 23/50\n",
      " - 5s - loss: 0.4609 - acc: 0.7840 - pre: 0.7276 - rec: 0.5629 - f1: 0.6339 - val_loss: 0.4836 - val_acc: 0.7722 - val_pre: 0.7032 - val_rec: 0.5496 - val_f1: 0.6160\n",
      "Epoch 24/50\n",
      " - 5s - loss: 0.4555 - acc: 0.7856 - pre: 0.7294 - rec: 0.5664 - f1: 0.6368 - val_loss: 0.4851 - val_acc: 0.7700 - val_pre: 0.6924 - val_rec: 0.5586 - val_f1: 0.6175\n",
      "Epoch 25/50\n",
      " - 5s - loss: 0.4538 - acc: 0.7878 - pre: 0.7322 - rec: 0.5731 - f1: 0.6420 - val_loss: 0.4846 - val_acc: 0.7700 - val_pre: 0.6951 - val_rec: 0.5519 - val_f1: 0.6144\n",
      "Epoch 26/50\n",
      " - 5s - loss: 0.4522 - acc: 0.7889 - pre: 0.7356 - rec: 0.5728 - f1: 0.6431 - val_loss: 0.4862 - val_acc: 0.7725 - val_pre: 0.7006 - val_rec: 0.5560 - val_f1: 0.6191\n",
      "Epoch 27/50\n",
      " - 5s - loss: 0.4519 - acc: 0.7887 - pre: 0.7315 - rec: 0.5781 - f1: 0.6450 - val_loss: 0.4852 - val_acc: 0.7721 - val_pre: 0.6991 - val_rec: 0.5557 - val_f1: 0.6185\n",
      "Epoch 28/50\n",
      " - 5s - loss: 0.4524 - acc: 0.7883 - pre: 0.7335 - rec: 0.5732 - f1: 0.6427 - val_loss: 0.4857 - val_acc: 0.7705 - val_pre: 0.6963 - val_rec: 0.5534 - val_f1: 0.6159\n",
      "Epoch 29/50\n",
      " - 5s - loss: 0.4466 - acc: 0.7933 - pre: 0.7418 - rec: 0.5834 - f1: 0.6523 - val_loss: 0.4848 - val_acc: 0.7716 - val_pre: 0.6947 - val_rec: 0.5626 - val_f1: 0.6208\n",
      "Epoch 30/50\n",
      " - 5s - loss: 0.4484 - acc: 0.7917 - pre: 0.7386 - rec: 0.5808 - f1: 0.6493 - val_loss: 0.4847 - val_acc: 0.7735 - val_pre: 0.6980 - val_rec: 0.5658 - val_f1: 0.6242\n",
      "Epoch 31/50\n",
      " - 5s - loss: 0.4505 - acc: 0.7903 - pre: 0.7342 - rec: 0.5816 - f1: 0.6481 - val_loss: 0.4847 - val_acc: 0.7712 - val_pre: 0.6970 - val_rec: 0.5557 - val_f1: 0.6176\n",
      "Epoch 32/50\n",
      " - 5s - loss: 0.4444 - acc: 0.7928 - pre: 0.7410 - rec: 0.5821 - f1: 0.6513 - val_loss: 0.4848 - val_acc: 0.7718 - val_pre: 0.6989 - val_rec: 0.5551 - val_f1: 0.6179\n",
      "Epoch 33/50\n",
      " - 6s - loss: 0.4442 - acc: 0.7925 - pre: 0.7401 - rec: 0.5818 - f1: 0.6506 - val_loss: 0.4840 - val_acc: 0.7741 - val_pre: 0.7028 - val_rec: 0.5592 - val_f1: 0.6221\n",
      "Epoch 34/50\n",
      " - 5s - loss: 0.4431 - acc: 0.7930 - pre: 0.7400 - rec: 0.5846 - f1: 0.6523 - val_loss: 0.4829 - val_acc: 0.7736 - val_pre: 0.7014 - val_rec: 0.5592 - val_f1: 0.6215\n",
      "Epoch 35/50\n",
      " - 5s - loss: 0.4457 - acc: 0.7903 - pre: 0.7362 - rec: 0.5778 - f1: 0.6467 - val_loss: 0.4836 - val_acc: 0.7751 - val_pre: 0.7023 - val_rec: 0.5652 - val_f1: 0.6256\n",
      "Epoch 36/50\n",
      " - 5s - loss: 0.4421 - acc: 0.7954 - pre: 0.7435 - rec: 0.5906 - f1: 0.6573 - val_loss: 0.4849 - val_acc: 0.7754 - val_pre: 0.7017 - val_rec: 0.5678 - val_f1: 0.6270\n",
      "Epoch 37/50\n",
      " - 5s - loss: 0.4398 - acc: 0.7963 - pre: 0.7439 - rec: 0.5935 - f1: 0.6593 - val_loss: 0.4849 - val_acc: 0.7759 - val_pre: 0.7019 - val_rec: 0.5704 - val_f1: 0.6288\n",
      "Epoch 38/50\n",
      " - 5s - loss: 0.4396 - acc: 0.7947 - pre: 0.7394 - rec: 0.5939 - f1: 0.6579 - val_loss: 0.4845 - val_acc: 0.7728 - val_pre: 0.6970 - val_rec: 0.5644 - val_f1: 0.6229\n",
      "Epoch 39/50\n",
      " - 5s - loss: 0.4381 - acc: 0.7968 - pre: 0.7439 - rec: 0.5954 - f1: 0.6607 - val_loss: 0.4864 - val_acc: 0.7729 - val_pre: 0.6996 - val_rec: 0.5609 - val_f1: 0.6218\n",
      "Epoch 40/50\n",
      " - 5s - loss: 0.4419 - acc: 0.7946 - pre: 0.7410 - rec: 0.5902 - f1: 0.6562 - val_loss: 0.4851 - val_acc: 0.7738 - val_pre: 0.7015 - val_rec: 0.5615 - val_f1: 0.6230\n",
      "Epoch 41/50\n",
      " - 5s - loss: 0.4371 - acc: 0.7975 - pre: 0.7470 - rec: 0.5941 - f1: 0.6609 - val_loss: 0.4838 - val_acc: 0.7754 - val_pre: 0.7007 - val_rec: 0.5716 - val_f1: 0.6290\n",
      "Epoch 42/50\n",
      " - 5s - loss: 0.4362 - acc: 0.7989 - pre: 0.7462 - rec: 0.6016 - f1: 0.6654 - val_loss: 0.4866 - val_acc: 0.7736 - val_pre: 0.6960 - val_rec: 0.5730 - val_f1: 0.6279\n",
      "Epoch 43/50\n",
      " - 5s - loss: 0.4387 - acc: 0.7953 - pre: 0.7420 - rec: 0.5917 - f1: 0.6577 - val_loss: 0.4869 - val_acc: 0.7727 - val_pre: 0.6987 - val_rec: 0.5626 - val_f1: 0.6225\n",
      "Epoch 44/50\n",
      " - 5s - loss: 0.4352 - acc: 0.7975 - pre: 0.7443 - rec: 0.5983 - f1: 0.6624 - val_loss: 0.4884 - val_acc: 0.7721 - val_pre: 0.6928 - val_rec: 0.5701 - val_f1: 0.6248\n",
      "Epoch 45/50\n",
      " - 5s - loss: 0.4355 - acc: 0.7982 - pre: 0.7444 - rec: 0.6010 - f1: 0.6641 - val_loss: 0.4887 - val_acc: 0.7720 - val_pre: 0.6963 - val_rec: 0.5615 - val_f1: 0.6209\n",
      "Epoch 46/50\n",
      " - 6s - loss: 0.4360 - acc: 0.7996 - pre: 0.7494 - rec: 0.6003 - f1: 0.6656 - val_loss: 0.4892 - val_acc: 0.7706 - val_pre: 0.6914 - val_rec: 0.5658 - val_f1: 0.6217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      " - 5s - loss: 0.4353 - acc: 0.7966 - pre: 0.7435 - rec: 0.5964 - f1: 0.6609 - val_loss: 0.4879 - val_acc: 0.7738 - val_pre: 0.7010 - val_rec: 0.5629 - val_f1: 0.6237\n",
      "Epoch 48/50\n",
      " - 5s - loss: 0.4336 - acc: 0.7992 - pre: 0.7489 - rec: 0.5990 - f1: 0.6648 - val_loss: 0.4883 - val_acc: 0.7728 - val_pre: 0.6980 - val_rec: 0.5635 - val_f1: 0.6228\n",
      "Epoch 49/50\n",
      " - 5s - loss: 0.4326 - acc: 0.8008 - pre: 0.7503 - rec: 0.6038 - f1: 0.6684 - val_loss: 0.4882 - val_acc: 0.7737 - val_pre: 0.7016 - val_rec: 0.5592 - val_f1: 0.6215\n",
      "Epoch 50/50\n",
      " - 5s - loss: 0.4310 - acc: 0.8000 - pre: 0.7491 - rec: 0.6012 - f1: 0.6663 - val_loss: 0.4915 - val_acc: 0.7706 - val_pre: 0.6898 - val_rec: 0.5673 - val_f1: 0.6219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13786cef0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train_pad, y_train, batch_size=64, epochs=50, validation_data=(X_test_pad, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 723  162  275]\n",
      " [ 182  452  245]\n",
      " [ 234  134 1050]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "y_pred = model.predict(X_test_pad)\n",
    "matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nicholson harika</td>\n",
       "      <td>4.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mükemmel derece kötü arkadaş sinema bilgi şüph...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mükemmel derece kötü bi film biselerin ol bekl...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beğen anla film film oyun senaryo zayıf film f...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ok harika bir film senaryo fazla ol yüksek per...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating Sentiment\n",
       "0                                 nicholson harika       4.0  positive\n",
       "1  mükemmel derece kötü arkadaş sinema bilgi şüph...     5.0  positive\n",
       "2  mükemmel derece kötü bi film biselerin ol bekl...     1.0  negative\n",
       "3  beğen anla film film oyun senaryo zayıf film f...     1.5  negative\n",
       "4  ok harika bir film senaryo fazla ol yüksek per...     5.0  positive"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import reviews dataset\n",
    "reviewspath = '/Users/pinarayaz/Jupyter/NLP/data/reviews_preprocessed.csv'\n",
    "reviews_df = pd.read_csv(reviewspath)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 1827\n",
      "Unique tokens:  47128\n",
      "Shape of entry tensor: (34990, 1827)\n",
      "Shape of emotion tensor: (34990,)\n"
     ]
    }
   ],
   "source": [
    "entries = reviews_df['Review'].values.astype('U').tolist()\n",
    "max_length = max([len(s.split()) for s in entries])\n",
    "print(\"Max length:\", max_length)\n",
    "\n",
    "#vectorize texts into 2d integer tensor\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(entries)\n",
    "sequences = tokenizer.texts_to_sequences(entries)\n",
    "\n",
    "#pad sequences\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Unique tokens: \", len(word_index))\n",
    "\n",
    "entry_pad = pad_sequences(sequences, maxlen=max_length)\n",
    "emotion = reviews_df['Sentiment'].values.astype('U')\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "emotion = lab_enc.fit_transform(emotion)\n",
    "\n",
    "print(\"Shape of entry tensor:\", entry_pad.shape)\n",
    "print(\"Shape of emotion tensor:\", emotion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47129\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(num_words,\n",
    "                           EMBEDDING_DIM,\n",
    "                           embeddings_initializer=Constant(embedding_matrix),\n",
    "                           input_length=max_length,\n",
    "                           trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', pre, rec, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_pad tensor: (27992, 1827)\n",
      "Shape of y_train tensor: (27992,)\n",
      "Shape of X_test_pad tensor: (6998, 1827)\n",
      "Shape of y_test tensor: (6998,)\n"
     ]
    }
   ],
   "source": [
    "#split the data\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "indices = np.arange(entry_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "entry_pad = entry_pad[indices]\n",
    "emotion = emotion[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * entry_pad.shape[0])\n",
    "\n",
    "X_train_pad = entry_pad[:-num_validation_samples]\n",
    "y_train = emotion[:-num_validation_samples]\n",
    "X_test_pad = entry_pad[-num_validation_samples:]\n",
    "y_test = emotion[-num_validation_samples:]\n",
    "print(\"Shape of X_train_pad tensor:\", X_train_pad.shape)\n",
    "print(\"Shape of y_train tensor:\", y_train.shape)\n",
    "print(\"Shape of X_test_pad tensor:\", X_test_pad.shape)\n",
    "print(\"Shape of y_test tensor:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27992 samples, validate on 6998 samples\n",
      "Epoch 1/5\n",
      "27992/27992 [==============================] - 286s 10ms/step - loss: 0.5543 - acc: 0.7269 - pre: 0.7398 - rec: 0.9412 - f1: 0.8277 - val_loss: 0.5328 - val_acc: 0.7481 - val_pre: 0.7510 - val_rec: 0.9591 - val_f1: 0.8417\n",
      "Epoch 2/5\n",
      "27992/27992 [==============================] - 299s 11ms/step - loss: 0.5329 - acc: 0.7416 - pre: 0.7582 - rec: 0.9270 - f1: 0.8334 - val_loss: 0.5222 - val_acc: 0.7581 - val_pre: 0.7620 - val_rec: 0.9531 - val_f1: 0.8462\n",
      "Epoch 3/5\n",
      "27992/27992 [==============================] - 282s 10ms/step - loss: 0.5204 - acc: 0.7506 - pre: 0.7674 - rec: 0.9238 - f1: 0.8377 - val_loss: 0.5093 - val_acc: 0.7608 - val_pre: 0.7749 - val_rec: 0.9297 - val_f1: 0.8445\n",
      "Epoch 4/5\n",
      "27992/27992 [==============================] - 330s 12ms/step - loss: 0.5104 - acc: 0.7587 - pre: 0.7753 - rec: 0.9235 - f1: 0.8422 - val_loss: 0.5024 - val_acc: 0.7672 - val_pre: 0.7807 - val_rec: 0.9300 - val_f1: 0.8481\n",
      "Epoch 5/5\n",
      "27992/27992 [==============================] - 307s 11ms/step - loss: 0.5031 - acc: 0.7623 - pre: 0.7790 - rec: 0.9228 - f1: 0.8441 - val_loss: 0.4967 - val_acc: 0.7691 - val_pre: 0.7876 - val_rec: 0.9196 - val_f1: 0.8477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x151192ac8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train_pad, y_train, batch_size=128, epochs=5, validation_data=(X_test_pad, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 854 1221]\n",
      " [ 395 4528]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "y_pred = model.predict_classes(X_test_pad)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
